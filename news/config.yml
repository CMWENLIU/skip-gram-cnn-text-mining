word_embeddings:
  # Two types of word embedding algorithm (word2vec and glove) are supported.
  # Just set the default to empty string to disable the word embeddings
  default: glove
  word2vec:
    path: ../../data/input/word_embeddings/GoogleNews-vectors-negative300.bin
    dimension: 300
    binary: True
  glove:
    path: '/home/xxliu10/bigdata/wordemb/vec_200.txt'
    dimension: 200
    length:

datasets:
  # Support currently 3 datasets: mrpolarity, 20newsgroup and localdata
  default: textinline
  textinline:
    business_data_file:
      path: "/home/xxliu10/bigdata/allNews/bbcready/b.txt"
      info: "Data source for the business data"
    enter_data_file:
      path: "/home/xxliu10/bigdata/allNews/bbcready/e.txt"
      info: "Data source for the enter data"
    politics_data_file:
      path: "/home/xxliu10/bigdata/allNews/bbcready/p.txt"
      info: "Data source for the politics data"
    sport_data_file:
      path: "/home/xxliu10/bigdata/allNews/bbcready/s.txt"
      info: "Data source for the sport data"
    tech_data_file:
      path: "/home/xxliu10/bigdata/allNews/bbcready/t.txt"
      info: "Data source for the tech data"
  20newsgroup:
    # The dataset includes following 20 newsgroups:
    # alt.atheism, comp.windows.x, rec.sport.hockey, soc.religion.christian
    # comp.graphics, misc.forsale, sci.crypt, talk.politics.guns
    # comp.os.ms-windows.misc, rec.autos, sci.electronics, talk.politics.mideast
    # comp.sys.ibm.pc.hardware, rec.motorcycles, sci.med, talk.politics.misc
    # comp.sys.mac.hardware, rec.sport.baseball, sci.space, talk.religion.misc
    categories:
      - alt.atheism
      - comp.graphics
      - sci.med
      - soc.religion.christian
    shuffle: True
    random_state: 42
  localdata:
    # Load text files with categories as subfolder names.
    # Individual samples are assumed to be files stored
    # a two levels folder structure such as the following:
    # container_folder/
    #   category_1_folder/
    #     file_1.txt file_2.txt ... file_42.txt
    #   category_2_folder/
    #     file_43.txt file_44.txt ...
    #
    # As an example, a SentenceCorpus dataset from
    # https://archive.ics.uci.edu/ml/datasets/Sentence+Classification
    # has been used. The dataset includes following 3 domains:
    # arxiv, jdm and plos
    container_path: ../../data/input/SentenceCorpus
    categories:
    shuffle: True
    random_state: 42

